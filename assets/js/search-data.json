{
  
    
        "post0": {
            "title": "Tabletoolz",
            "content": "Implementing Tabletoolz for SqlAlchemy . Abstract . Tabletoolz is a python library which provides users with data manipulation approaches used in R’s Dplyr to manipulate tables in SQL and Pyspark. It aims to provide an experience where a user can use R’s Dplyr approach for data manipulation in Python. This paper outlines methods of how this package was implemented accompanied by results of the objective achieved. If a user has used Dplyr, is familiar with its piping capabilities to chain functions together and is looking to work with SQL tables in Python, this is the library to check out! . Background . There are many widely used data manipulation packages today in the data science ecosystem. A few names that come up are Dplyr in R and Pandas in Python. However, the style that we are trying to emulate comes from Dplyr. Dplyr is unique in that it has a pipe operator that enables function chaining. On top of that, it builds on its data vocabulary that makes every sequence of action flow nicely. One library in Python that tries to recreate the Dplyr style of data manipulation using the Python Pandas library is dfply. It uses a decorator-based architecture for the piping functionality with the goal of making it concise and easily extensible. With that said, Tabletoolz borrows decorators and pipes from dfply to be used to extend these functionalities to the library. The library already has the foundations of working with SQL tables built. . Introduction . Data manipulation is the way in which data can be manipulated and changed. It is the part of the data science workflow that stands between sourcing your data and modelling your data. Without processing your data, your data would not necessarily be in the right form to conduct analysis on. There are many ways in which you can perform data manipulation, one of which is by using the grammar of data manipulation. The grammar of data manipulation provides a consistent set of verbs that solves the most common data manipulation problems, popularized by Hadley Wickham, creator of R’s Tidyverse, a collection of packages designed for data science (Wickham, 2014) In Python, there have been efforts made to reproduce this approach in the likes of dfply for Pandas which this project takes inspiration and borrows from. However, we do not yet have such libraries for SQL and PySpark where we can follow these processes of that in the Tidyverse. . With Tabletoolz, we wanted to improve the tools available in python data management. Our objective was to implement SqlAlchemy into the package by writing functions that work with SQL tables using the grammars for data manipulation (Wickham, 2014). Aside from writing functions, good testing practice was done on each function to ensure that these functions perform as expected. Lastly, documentation was written for each function. On top of the main objectives, some of the additional goals are improving proficiency in software engineering by learning how to write functions that solve data manipulation problems. Additionally, I wanted to gain experience in the development cycle of a software project by learning to compile code into a Python package. . Methods . To get started, I had to understand what I was working with. The libraries that were available to me were Python and SqlAlchemy. SqlAlchemy is the Python SQL toolkit that gives application developers the full power and flexibility of SQL. As per the SqlAlchemy documentation, “It provides a full suite of well-known enterprise-level persistence patterns, designed for efficient and high-performing database access, adapted into a simple and Pythonic domain language.” Due to the fact that most of the foundational code was already build, my role was to complete the library with functional functions of data manipulation. Below is a figure describing the process. . . It all starts with an idea of what the function does. Take for example the select function. It chooses variables from the table and keeps only the variables chosen. I then check to see if SqlAlchemy already has that implemented. If it does, then a wrapper function goes on top of the pre-existing function. A wrapper function is composed of a decorator like @pipeable (this gives the function capabilities to pipe like R’s Dplyr) and some code tweaks to the function to make it compatible with the library. After the code works, it goes through testing to see if it really works. Testing involves searching for edge cases to break the function. This ensures that the function is robust and accounts for all foreseeable mistakes that a user makes. If everything works as intended, the code can be documented. The docstring describes what the function does. For every function coded, a docstring is written for it. It describes what the functions does, inputs that go into the functions and outputs, alongside types that should be used. If in an event that the code does not work, I go back to the drawing board and draw up new ideas and go through the process again. . Results . In this section, I will layout the three outcomes achieved in the project. The first “writing functions” is shown with an example of the arrange function from Figure 2. Its usage is to sort a table in either ascending or descending order according to the columns supplied to it. The second objective “writing documentations” (After the def statement in Figure 2) is annotated with “”” strings “”” within its function cell to provide information on how the function work and what the inputs and outputs should be. Additionally, the user is cautioned if there are limits that they should be aware of when using the function. . Functions . Arrange changes the ordering of the rows. | . Helper functions . On top of writing functions, one important aspect I would like to highlight is writing helper functions which provides some useful functionality to complement the main functions within the library. Figure 3 shows examples of helper functions written for the library. The first function intersperse aids the unite function in adding a column separator that unites each column. The following two functions get_onclause_col and table_check are preliminary checks to make sure joins can be performed on tables. . . Writing tests . The third and final objective is to “write tests”. The methods used for testing are asserting whether the results are the same if one were to do it in pandas (asserting data frames), trying inputs of different data types to break the function and raising exceptions if the data type is not compatible with the function. I implemented several scenarios in Figure 4. The first function, test_rename, takes the response function and tests it to see whether its output matches that of the operation if done in the same way using the Python Pandas library. The second function, test_rename_exception, is to test the outcomes of using different types of inputs to see which inputs are not compatible with the function. The inputs that crash the function may have a different data type that is not supported by the function; therefore, we would have to account for these cases during documentation. . . Discussion . After going through the results of the project, I will discuss how the package can be used in a setting where it might be used. For example, we are working with a “Car Options” table that contains information about the options that can be modified onto your car. Say we would like to compute the average of each option. First we would have to import the libraries needed which are TableToolz and SqlAlchemy as shown in Figure 6. . . Next, Figure 7 shows best practices in Tabletoolz by first turning tables into a statement as SQL works with statements. Additionally, a user can print the statement to see what it looks like and return the results of the table by turning the statement into a pandas dataframe. . . Lastly, Figure 8 shows how we would solve a standard data problem in TableToolz. We first define the Mean function then turn the table into a statement, have the variable that we would like to group by and mutate a new variable to compute its average. Then, we can select the columns that we would like to return and finally return its results by turning it into a pandas dataframe. . . Conclusion . In conclusion, I have gone through the goals of the project, methods involved from ideas to coding, documentation and finally testing. All in all, I have written a total of 7 functions for TableToolz Sql which are arrange, drop, rename, unite, left join, inner join, group by. Throughout the course of this project, I have learned a lot about software engineering. The first is going from conceptualizing ideas such as learning about how the functions work and what is it supposed to do then breaking it down into smaller chunks and then translating it into code. I have found that it gave me a better understanding of how it works as a whole. I have also learnt about the importance of testing to make the code more robust and least likely to fail through multiple perspective of test that I have mentioned above. Also the importance of documentations cannot be missed because it provides meaning to the function and how it is used. I wrote documentation for every function in the library. Lastly, on top of the objectives that were achieved, I also learned about structuring directories, cleaning up and organizing files into appropriate folders. . Overall, this capstone project was successful. The objectives met are shown in the results and an example under the discussions section shows a full example of how TableToolz can be incorporated into one’s workflow. In spite of this, there are some limitations to be highlighted, mainly the core SqlAlchemy library where there is not a lot of core data manipulation functions built in compared to libraries like Dplyr. Due to this limitation, a lot of wrangling has to be done in python to find a workaround to implement these functions. However this project can be improved. In the future, refactoring can be done to improve the readability of the code base and more additional functions can be ported into the SQL portion of the library. On top of that, the Pyspark portion remains a work in progress therefore some help could go there. . Acknowledgements . I would like to thank Dr Iverson for giving me an opportunity to contribute to this project. . References . Wickham, Hadley &amp; François, Romain. (2014). dplyr: A Grammar of Data Manipulation. . Dfply https://github.com/kieferk/dfply . SqlAlchemy https://docs.sqlalchemy.org/en/13/core/ . Python https://www.python.org/ . Appendix . Functions . Drop, drops columns from the data frame. . | Group-by allows operations to be performed by “group” . | Rename, changes the name of a column. . | Unite, concatenates columns together. . | Inner join joins tables using the inner join method. . | Left join joins tables using the left join method. . | . Testing . . .",
            "url": "https://dqniellew1.github.io/dqniellew/markdown/paper/data%20manipulation/projects/2020/06/05/Tabletoolz.html",
            "relUrl": "/markdown/paper/data%20manipulation/projects/2020/06/05/Tabletoolz.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Tabletoolz demonstration",
            "content": "About . In my last post, I wrote about my motivations, methods and results on Tabletoolz. This post will give a demonstration of how the Tabletoolz library can be used. . The libraries we will be working with are SqlAlchemy and TableToolz. . # imports import tabletoolz.sql as tbs from tabletoolz.sql import T, D from sqlalchemy.orm import sessionmaker from sqlalchemy import create_engine from sqlalchemy.ext.automap import automap_base; . # Set-up the database engine = create_engine(&quot;sqlite:///tabletoolz/databases/Car_Database.db&quot;) Base = automap_base() Base.prepare(engine, reflect=True) # Assign the tables brands = Base.classes.Brands car_options = Base.classes.Car_Options car_vins = Base.classes.Car_Vins customer_ownership = Base.classes.Customer_Ownership dealers = Base.classes.Dealers manufacture_plant = Base.classes.Manufacture_Plant models = Base.classes.Models . In Python, libaries such as dfply makes function chaining possible through the use of pipes which is similar to R&#39;s dplyr. Tabletoolz_Sql borrows from dfply to achieve this method of data manipulation. . After loading your tables, . Important: every operation begins by turning a table into a statement. . df = car_options &gt;&gt; tbs.to_statement . . Tip: Statements can be printed in the SQL format. . df = car_options &gt;&gt; tbs.to_statement &gt;&gt; tbs.pprint . SELECT &#34;Car_Options&#34;.option_set_id, &#34;Car_Options&#34;.model_id, &#34;Car_Options&#34;.engine_id, &#34;Car_Options&#34;.transmission_id, &#34;Car_Options&#34;.chassis_id, &#34;Car_Options&#34;.premium_sound_id, &#34;Car_Options&#34;.color, &#34;Car_Options&#34;.option_set_price FROM &#34;Car_Options&#34; . A common data manipulation task . Let&#39;s say we want to compute the Mean of the model base prices. We can begin by turning the table into a statement. Group-by our column of interest and compute the Mean statistic. Finally, we can select the columns we want to output and turn it into a dataframe. . Mean = tbs.sql_func(&#39;avg&#39;) . # Mutate df = (models &gt;&gt; tbs.to_statement &gt;&gt; tbs.group_by([T.brand_id]) &gt;&gt; tbs.mutate(model_base_prices = Mean(T.model_base_price)) &gt;&gt; tbs.select([T.brand_id,&#39;model_base_prices&#39;]) &gt;&gt; tbs.head(num=5) &gt;&gt; tbs.to_pandas(engine)); df . brand_id model_base_prices . 0 1 | 25666.666667 | . 1 2 | 24666.666667 | . 2 3 | 14666.666667 | . 3 4 | 102500.000000 | . 4 5 | 32500.000000 | . Other data manipulation tasks . Arrange . Columns can be arranged either in ascending or descending order. . df = (car_options &gt;&gt; tbs.to_statement &gt;&gt; tbs.arrange([T.option_set_price, T.model_id, &quot;engine_id&quot;], ascending=True) &gt;&gt; tbs.head(num=5) &gt;&gt; tbs.to_pandas(engine)); df . option_set_id model_id engine_id transmission_id chassis_id premium_sound_id color option_set_price . 0 26 | 11 | 2 | 4 | 6 | NaN | Magenta | 200 | . 1 25 | 1 | 2 | 4 | 7 | NaN | Red | 900 | . 2 12 | 1 | 1 | 4 | 7 | NaN | Black | 1100 | . 3 3 | 6 | 1 | 4 | 7 | 5.0 | Green | 1100 | . 4 2 | 5 | 2 | 4 | 6 | 5.0 | Yellow | 1200 | . Renaming a column . df = (car_options &gt;&gt; tbs.to_statement &gt;&gt; tbs.rename(COLOUR=T.color, PRICE=T.option_set_price) &gt;&gt; tbs.head(num=5) &gt;&gt; tbs.to_pandas(engine)); df . option_set_id model_id engine_id transmission_id chassis_id premium_sound_id COLOUR PRICE . 0 1 | 4 | 2 | 4 | 6 | 5 | Blue | 2000 | . 1 2 | 5 | 2 | 4 | 6 | 5 | Yellow | 1200 | . 2 3 | 6 | 1 | 4 | 7 | 5 | Green | 1100 | . 3 4 | 15 | 1 | 4 | 7 | 5 | Red | 4000 | . 4 5 | 14 | 2 | 4 | 7 | 5 | Sky | 3000 | . Unite columns with a separator . df = (car_options &gt;&gt; tbs.to_statement &gt;&gt; tbs.unite([T.chassis_id, T.option_set_price, T.color], &quot;UNITED_COL&quot;, sep=&#39;_&#39;, remove=True) &gt;&gt; tbs.head(num=5) &gt;&gt; tbs.to_pandas(engine) ); df . option_set_id model_id engine_id transmission_id premium_sound_id UNITED_COL . 0 1 | 4 | 2 | 4 | 5 | 6_2000_Blue | . 1 2 | 5 | 2 | 4 | 5 | 6_1200_Yellow | . 2 3 | 6 | 1 | 4 | 5 | 7_1100_Green | . 3 4 | 15 | 1 | 4 | 5 | 7_4000_Red | . 4 5 | 14 | 2 | 4 | 5 | 7_3000_Sky | . Performing joins . Joins can be performed by specifying the tables that you want to join and the columns to join on. . Table1 = car_options &gt;&gt; tbs.to_statement Table2 = car_vins &gt;&gt; tbs.to_statement . # Columns to join on Cols = (Table1.c.model_id== Table2.c.model_id) &amp; (Table1.c.option_set_id == Table2.c.option_set_id) . df = (Table1 &gt;&gt; tbs.left_join(Table2, onclause=Cols) &gt;&gt; tbs.head(num=5) &gt;&gt; tbs.to_pandas(engine)); df . option_set_id model_id engine_id transmission_id chassis_id premium_sound_id color option_set_price vin model_id option_set_id manufactured_date manufactured_plant_id . 0 1 | 4 | 2 | 4 | 6 | 5 | Blue | 2000 | 5.0 | 4.0 | 1.0 | 2013-06-22 | 4.0 | . 1 2 | 5 | 2 | 4 | 6 | 5 | Yellow | 1200 | NaN | NaN | NaN | None | NaN | . 2 3 | 6 | 1 | 4 | 7 | 5 | Green | 1100 | NaN | NaN | NaN | None | NaN | . 3 4 | 15 | 1 | 4 | 7 | 5 | Red | 4000 | NaN | NaN | NaN | None | NaN | . 4 5 | 14 | 2 | 4 | 7 | 5 | Sky | 3000 | 2.0 | 14.0 | 5.0 | 2016-09-19 | 3.0 | . For more info on the library: 1 . 1. Visit the github.↩ .",
            "url": "https://dqniellew1.github.io/dqniellew/jupyter/data%20manipulation/projects/2020/06/05/How_to_use_Tabletoolz.html",
            "relUrl": "/jupyter/data%20manipulation/projects/2020/06/05/How_to_use_Tabletoolz.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://dqniellew1.github.io/dqniellew/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://dqniellew1.github.io/dqniellew/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Daniel Lew. I recently graduated from college with a bachelor’s degree in Data Science. This space will be used to write about my projects, experiences, and topics surrounding data science that interest me. . I am acticely looking for a job in a data-related position; Data Analyst, Data Scientist. .",
          "url": "https://dqniellew1.github.io/dqniellew/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dqniellew1.github.io/dqniellew/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}